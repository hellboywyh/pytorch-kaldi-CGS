{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f8068dcf66dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_configs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_avg_performance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mread_args_command_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_shell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_n_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_all_archs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_item2sec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdump_epoch_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_curves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_lr_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_str_ep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import configparser\n",
    "# import ConfigParser as configparser\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import check_cfg, create_lists, create_configs, compute_avg_performance, \\\n",
    "    read_args_command_line, run_shell, compute_n_chunks, get_all_archs, cfg_item2sec, \\\n",
    "    dump_epoch_results, create_curves, change_lr_cfg, expand_str_ep, model_init, optimizer_init\n",
    "from shutil import copyfile\n",
    "import re\n",
    "from distutils.util import strtobool\n",
    "import importlib\n",
    "import math\n",
    "import threading\n",
    "from data_io import read_lab_fea, open_or_fd, write_mat\n",
    "from pattern_search import pattern_prun_model\n",
    "\n",
    "cfg_file = '/yhwang/0-Projects/0-kaldi-lstm/2-pytorch-kaldi-cgs/cfg/20201021_Pattern_Search/TIMIT_LSTM_fmllr_L2_8bw_16ba_wohcgs_v1_16_8x8_8.cfg'\n",
    "\n",
    "if not (os.path.exists(cfg_file)):\n",
    "    sys.stderr.write('ERROR: The config file %s does not exist!\\n' % (cfg_file))\n",
    "    sys.exit(0)\n",
    "else:\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(cfg_file)\n",
    "\n",
    "    # Log file path\n",
    "log_file = config['exp']['out_folder'] + '/log.log'\n",
    "\n",
    "# Read, parse, and check the config file\n",
    "cfg_file_proto = config['cfg_proto']['cfg_proto']\n",
    "[config, name_data, name_arch] = check_cfg(cfg_file, config, cfg_file_proto)\n",
    "\n",
    "out_folder = config['exp']['out_folder']\n",
    "forward_save_files = list(map(strtobool, config['forward']['save_out_file'].split(',')))\n",
    "is_production = strtobool(config['exp']['production'])\n",
    "\n",
    "# --------DECODING--------#\n",
    "dec_lst = glob.glob(out_folder + '/exp_files/*_to_decode.ark')\n",
    "\n",
    "forward_data_lst = config['data_use']['forward_with'].split(',')\n",
    "forward_outs = config['forward']['forward_out'].split(',')\n",
    "forward_dec_outs = list(map(strtobool, config['forward']['require_decoding'].split(',')))\n",
    "\n",
    "for data in forward_data_lst:\n",
    "    for k in range(len(forward_outs)):\n",
    "        if forward_dec_outs[k]:\n",
    "\n",
    "            print('Decoding %s output %s' % (data, forward_outs[k]))\n",
    "\n",
    "            info_file = out_folder + '/exp_files/decoding_' + data + '_' + forward_outs[k] + '.info'\n",
    "\n",
    "            # create decode config file\n",
    "            config_dec_file = out_folder + '/decoding_' + data + '_' + forward_outs[k] + '.conf'\n",
    "            config_dec = configparser.ConfigParser()\n",
    "            config_dec.add_section('decoding')\n",
    "\n",
    "            for dec_key in config['decoding'].keys():\n",
    "                config_dec.set('decoding', dec_key, config['decoding'][dec_key])\n",
    "\n",
    "            # add graph_dir, datadir, alidir\n",
    "            lab_field = config[cfg_item2sec(config, 'data_name', data)]['lab']\n",
    "\n",
    "            # Production case, we don't have labels\n",
    "            if not is_production:\n",
    "                pattern = 'lab_folder=(.*)\\nlab_opts=(.*)\\nlab_count_file=(.*)\\nlab_data_folder=(.*)\\nlab_graph=(.*)'\n",
    "                alidir = re.findall(pattern, lab_field)[0][0]\n",
    "                config_dec.set('decoding', 'alidir', os.path.abspath(alidir))\n",
    "\n",
    "                datadir = re.findall(pattern, lab_field)[0][3]\n",
    "                config_dec.set('decoding', 'data', os.path.abspath(datadir))\n",
    "\n",
    "                graphdir = re.findall(pattern, lab_field)[0][4]\n",
    "                config_dec.set('decoding', 'graphdir', os.path.abspath(graphdir))\n",
    "            else:\n",
    "                pattern = 'lab_data_folder=(.*)\\nlab_graph=(.*)'\n",
    "                datadir = re.findall(pattern, lab_field)[0][0]\n",
    "                config_dec.set('decoding', 'data', os.path.abspath(datadir))\n",
    "\n",
    "                graphdir = re.findall(pattern, lab_field)[0][1]\n",
    "                config_dec.set('decoding', 'graphdir', os.path.abspath(graphdir))\n",
    "\n",
    "                # The ali dir is supposed to be in exp/model/ which is one level ahead of graphdir\n",
    "                alidir = graphdir.split('/')[0:len(graphdir.split('/')) - 1]\n",
    "                alidir = \"/\".join(alidir)\n",
    "                config_dec.set('decoding', 'alidir', os.path.abspath(alidir))\n",
    "\n",
    "            with open(config_dec_file, 'w') as configfile:\n",
    "                config_dec.write(configfile)\n",
    "\n",
    "            out_folder = os.path.abspath(out_folder)\n",
    "            files_dec = out_folder + '/exp_files/forward_' + data + '_ep*_ck*_' + forward_outs[k] + '_to_decode.ark'\n",
    "            out_dec_folder = out_folder + '/decode_' + data + '_' + forward_outs[k]\n",
    "\n",
    "            if not (os.path.exists(info_file)):\n",
    "\n",
    "                # Run the decoder\n",
    "                cmd_decode = cmd + config['decoding']['decoding_script_folder'] + '/' + config['decoding'][\n",
    "                    'decoding_script'] + ' ' + os.path.abspath(\n",
    "                    config_dec_file) + ' ' + out_dec_folder + ' \\\"' + files_dec + '\\\"'\n",
    "                run_shell(cmd_decode, log_file)\n",
    "\n",
    "                # remove ark files if needed\n",
    "                if not forward_save_files[k]:\n",
    "                    list_rem = glob.glob(files_dec)\n",
    "                    for rem_ark in list_rem:\n",
    "                        os.remove(rem_ark)\n",
    "\n",
    "            # Print WER results and write info file\n",
    "            cmd_res = './check_res_dec.sh ' + out_dec_folder\n",
    "            wers = run_shell(cmd_res, log_file).decode('utf-8')\n",
    "            res_file = open(res_file_path, \"a\")\n",
    "            res_file.write('%s\\n' % wers)\n",
    "            print(wers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
